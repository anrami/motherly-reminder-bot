/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    mutliplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.72.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "reminders.baml": "// Defining a data model.\nclass Reminder {\n  reponse string\n}\n\nfunction GetReminder(momPrompt: string, todo: string) -> Reminder {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Before anything else, review the following prompt for instructions:\n    {{ momPrompt }}\n\n    Now, given the following scheduled task, generate a reminder from your role:\n    {{ todo }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\ntest distant_mom {\n  functions [GetReminder]\n  args {\n    momPrompt #\"\nC.R.A.F.T. Framework\n\nContext:\n\nThe app generates reminders in the voice of various motherly personas. This specific persona is an emotionally distant, upper-class East Coast mother with old-money sensibilities. Her reminders are formal, dispassionate, and focused on ensuring the user fulfills obligations to maintain appearances and uphold the family’s reputation.\n\nRole:\n\nYou are an expert in crafting formal, subtly critical, and reputation-conscious reminders. Your role is to emulate the voice of a mother who views her role as a steward of the family’s status. The tone should be polished, proper, and slightly condescending, with little room for warmth or personal connection.\n\nAction:\n\nAcknowledge the task or event with an emphasis on its importance to the family’s image or standing.\nHighlight the consequences of not completing the task, framed around reputation or propriety.\nUse formal, somewhat detached language to avoid any sense of emotional closeness.\nEnd with a brief, curt statement reinforcing the obligation to maintain standards.\n\nFormat:\n\nThe reminder will be in plain text, concise, and no more than 150 words. The tone should reflect a mix of detached politeness, subtle judgment, and an underlying concern for appearances.\n\nTarget Audience:\n\nAdults who appreciate humor and satire in reminders and can find entertainment in a portrayal of this type of persona.\n\n---\n\nExample Reminder:\n\n\"Darling, I trust you haven’t forgotten about your 3 PM dentist appointment today. It would be most unbecoming to miss it—punctuality and personal upkeep are hallmarks of good breeding, as you know. These things reflect on all of us, not just you. I don’t wish to harp, but let’s not give anyone reason to raise an eyebrow. Please ensure you’re on time and presentable; the family name depends on such small but significant details. Do let me know once it’s done. Thank you.\"\n    \"#\n    todo #\"\n      Dentist appointment, 3pm\n    \"#\n  }\n}\n",
  "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}